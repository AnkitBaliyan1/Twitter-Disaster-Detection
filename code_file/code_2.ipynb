{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling file data\n",
    "import pandas as pd\n",
    "# handling numerical data\n",
    "import numpy as np\n",
    "# for ploting/visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# importing Natural Language Toolkit\n",
    "import nltk\n",
    "\n",
    "# removing stopwords\n",
    "from nltk.corpus import stopwords\n",
    "# lamatize text data\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/ankitbaliyan/Documents/VS_Code/NLP_Disaster/dataset/train.csv\")\n",
    "test = pd.read_csv(\"/Users/ankitbaliyan/Documents/VS_Code/NLP_Disaster/dataset/test.csv\")\n",
    "submission = pd.read_csv(\"/Users/ankitbaliyan/Documents/VS_Code/NLP_Disaster/dataset/sample_sub.csv\")\n",
    "\n",
    "train=train[['text','target']]\n",
    "test=test[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating train and test data\n",
    "i= train.shape[0]\n",
    "train = data.iloc[:i]\n",
    "test = data.iloc[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>69</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>133</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...      69     1.0\n",
       "1             Forest fire near La Ronge Sask. Canada      38     1.0\n",
       "2  All residents asked to 'shelter in place' are ...     133     1.0\n",
       "3  13,000 people receive #wildfires evacuation or...      65     1.0\n",
       "4  Just got sent this photo from Ruby #Alaska as ...      88     1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/586650901.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(nltk.word_tokenize)\n",
      "/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/586650901.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: [word.lower() for word in x])\n",
      "/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/586650901.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
      "/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/586650901.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
      "/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/586650901.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: [re.sub(r\"[^a-zA-Z0-9]\", \"\", word) for word in x])\n",
      "/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/586650901.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: [re.sub(r\"\\d+\", \"NUM\", word) for word in x])\n",
      "/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/586650901.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda x: [re.sub(r\"#\\w+\", \"\", word) for word in x])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.91      0.83       874\n",
      "         1.0       0.83      0.64      0.72       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.80      0.77      0.78      1523\n",
      "weighted avg       0.80      0.79      0.78      1523\n",
      "\n",
      "Accuracy: 0.7905449770190414\n"
     ]
    }
   ],
   "source": [
    "preprocess_and_train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/Users/ankitbaliyan/Documents/VS_Code/NLP_Disaster/dataset/train.csv\")\n",
    "test = pd.read_csv(\"/Users/ankitbaliyan/Documents/VS_Code/NLP_Disaster/dataset/test.csv\")\n",
    "submission = pd.read_csv(\"/Users/ankitbaliyan/Documents/VS_Code/NLP_Disaster/dataset/sample_sub.csv\")\n",
    "\n",
    "train=train[['text','target']]\n",
    "test=test[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 2)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def preprocess_train_predict(train, test):\n",
    "    df=pd.concat([train, test], axis=0)\n",
    "    df.shape\n",
    "\n",
    "    # Tokenization\n",
    "    df['text'] = df['text'].apply(nltk.word_tokenize)\n",
    "    \n",
    "    # Text Lowercasing\n",
    "    df['text'] = df['text'].apply(lambda x: [word.lower() for word in x])\n",
    "    \n",
    "    # Stop Word Removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['text'] = df['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['text'] = df['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "    \n",
    "    # Removing Special Characters and Punctuation\n",
    "    df['text'] = df['text'].apply(lambda x: [re.sub(r\"[^a-zA-Z0-9]\", \"\", word) for word in x])\n",
    "    \n",
    "    # Handling Numerical Values and # Words\n",
    "    df['text'] = df['text'].apply(lambda x: [re.sub(r\"\\d+\", \"NUM\", word) for word in x])\n",
    "    df['text'] = df['text'].apply(lambda x: [re.sub(r\"#\\w+\", \"\", word) for word in x])\n",
    "\n",
    "    \n",
    "    # Vectorization\n",
    "    vectorizer = TfidfVectorizer()    \n",
    "    X_train_df = vectorizer.fit_transform(train['text'].apply(lambda x: \" \".join(x)))\n",
    "    X_test_df = vectorizer.transform(test['text'].apply(lambda x: \" \".join(x)))\n",
    "    y_train = train['target']\n",
    "\n",
    "    \n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_df, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Build the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model2 = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    model2.fit(X_train_df, y_train)\n",
    "    \n",
    "    # Predict on the validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_test_pred = model2.predict(X_test_df)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    classification_repor = classification_report(y_val, y_pred)\n",
    "    accuracy = model.score(X_val, y_val)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_repor)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    return (y_test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/692380678.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreprocess_train_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/js/fsn_mzw97y33gfyf27km75kh0000gn/T/ipykernel_10043/233091743.py\u001b[0m in \u001b[0;36mpreprocess_train_predict\u001b[0;34m(train, test)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Vectorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mX_train_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mX_test_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2075\u001b[0m         \"\"\"\n\u001b[1;32m   2076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1330\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1221\u001b[0m                     \u001b[0;34m\"empty vocabulary; perhaps the documents only contain stop words\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "preprocess_train_predict(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def preprocess(train_df, test_df):\n",
    "    # Concatenate train and test data for consistent preprocessing\n",
    "    combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "    # Tokenization\n",
    "    \n",
    "    combined_df['text'] = combined_df['text'].apply(nltk.word_tokenize)\n",
    "\n",
    "    # Text Lowercasing\n",
    "    combined_df['text'] = combined_df['text'].apply(lambda x: [word.lower() for word in x])\n",
    "\n",
    "    # Stop Word Removal\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    combined_df['text'] = combined_df['text'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "    # Lemmatization\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    combined_df['text'] = combined_df['text'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "    # Removing Special Characters and Punctuation\n",
    "    combined_df['text'] = combined_df['text'].apply(lambda x: [re.sub(r\"[^a-zA-Z0-9]\", \"\", word) for word in x])\n",
    "\n",
    "    # Handling Numerical Values and # Words\n",
    "    combined_df['text'] = combined_df['text'].apply(lambda x: [re.sub(r\"\\d+\", \"NUM\", word) for word in x])\n",
    "    combined_df['text'] = combined_df['text'].apply(lambda x: [re.sub(r\"#\\w+\", \"\", word) for word in x])\n",
    "\n",
    "    # Filter out documents that are empty or contain only stop words\n",
    "    combined_df['text'] = combined_df['text'].apply(lambda x: [word for word in x if word.strip() != ''])\n",
    "    combined_df = combined_df[combined_df['text'].apply(lambda x: len(x) > 0)]\n",
    "    return combined_df\n",
    "\n",
    "    \"\"\"\n",
    "    # Vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train = vectorizer.fit_transform(train_df['text'].apply(lambda x: \" \".join(x)))\n",
    "    X_test = vectorizer.transform(test_df['text'].apply(lambda x: \" \".join(x)))\n",
    "    y_train = train_df['target']\n",
    "\n",
    "    # Check if vocabulary is empty\n",
    "    if not vectorizer.vocabulary_:\n",
    "        raise ValueError(\"Empty vocabulary. Check the preprocessing steps, as all documents may contain only stop words.\")\n",
    "\n",
    "    # Build the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return y_pred\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = preprocess(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (7613, 2)\n",
      "test: (3262, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[happened, terrible, car, crash]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[heard, earthquake, different, city, stay, saf...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[forest, fire, spot, pond, goose, fleeing, acr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[apocalypse, lighting, spokane, wildfire]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[typhoon, soudelor, kill, NUM, china, taiwan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0                   [happened, terrible, car, crash]     NaN\n",
       "1  [heard, earthquake, different, city, stay, saf...     NaN\n",
       "2  [forest, fire, spot, pond, goose, fleeing, acr...     NaN\n",
       "3          [apocalypse, lighting, spokane, wildfire]     NaN\n",
       "4      [typhoon, soudelor, kill, NUM, china, taiwan]     NaN"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating train and test data\n",
    "i= train.shape[0]\n",
    "train = combined_df.iloc[:i]\n",
    "test = combined_df.iloc[i:]\n",
    "print(\"train:\",train.shape)\n",
    "print(\"test:\",test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_df, test_df):\n",
    "    # Vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_train = vectorizer.fit_transform(train_df['text'].apply(lambda x: \" \".join(x)))\n",
    "    X_test = vectorizer.transform(test_df['text'].apply(lambda x: \" \".join(x)))\n",
    "    y_train = train_df['target']\n",
    "\n",
    "    # Check if vocabulary is empty\n",
    "    if not vectorizer.vocabulary_:\n",
    "        raise ValueError(\"Empty vocabulary. Check the preprocessing steps, as all documents may contain only stop words.\")\n",
    "\n",
    "    # Build the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = predict(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='0'>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(test_pred).value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
