{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling file data\n",
    "import pandas as pd\n",
    "# handling numerical data\n",
    "import numpy as np\n",
    "# for ploting/visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "# importing Natural Language Toolkit\n",
    "import nltk\n",
    "\n",
    "# data pre-processing\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# transform data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "# model building\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 5)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"/Users/ankitbaliyan/Documents/VS_Code/Ongoing projects/NLP_Disaster/dataset/train.csv\")\n",
    "test = pd.read_csv(\"/Users/ankitbaliyan/Documents/VS_Code/Ongoing projects/NLP_Disaster/dataset/test.csv\")\n",
    "submission = pd.read_csv(\"//Users/ankitbaliyan/Documents/VS_Code/Ongoing projects/NLP_Disaster/dataset/sample_sub.csv\")\n",
    "\n",
    "# merging datasets \n",
    "data=pd.concat([train, test], axis=0)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of text when Disaster: 108.11342097217977\n",
      "Mean length of text when No Disaster: 95.70681713496084\n"
     ]
    }
   ],
   "source": [
    "data['length'] = data['text'].apply(lambda x: len(x))\n",
    "print(\"Mean length of text when Disaster:\",data[data['target']==1].length.mean())\n",
    "print(\"Mean length of text when No Disaster:\",data[data['target']==0].length.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case\n",
    "data['text']=data['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the words that starts with #\n",
    "data[\"#word\"] = data['text'].apply(lambda x: list(word for word in x.split() if word[0]=='#'))\n",
    "\n",
    "# count # words in the text column\n",
    "data['number_of_#words']=data['#word'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of #words in tweeets from Disaster 0.5090186487312749\n",
      "Average number of #words in tweeets from No Disaster 0.38576692768309534\n"
     ]
    }
   ],
   "source": [
    "# check averange numbr of #words in tweet with disaster and not disaster\n",
    "print(\"Average number of #words in tweeets from Disaster\",data[data['target']==1]['number_of_#words'].mean())\n",
    "print(\"Average number of #words in tweeets from No Disaster\",data[data['target']==0]['number_of_#words'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>#word</th>\n",
       "      <th>number_of_#words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>[#earthquake]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>[#wildfires]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>[#alaska, #wildfires]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#rockyfire update =&gt; california hwy. 20 closed...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>[#rockyfire, #cafire, #wildfires]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster heavy rain causes flash flood...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95</td>\n",
       "      <td>[#flood, #disaster]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm on top of the hill and i can see a fire in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there's an emergency evacuation happening now ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this #earthquake m...   \n",
       "1   4     NaN      NaN             forest fire near la ronge sask. canada   \n",
       "2   5     NaN      NaN  all residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby #alaska as ...   \n",
       "5   8     NaN      NaN  #rockyfire update => california hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  i'm on top of the hill and i can see a fire in...   \n",
       "8  14     NaN      NaN  there's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  i'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  length                              #word  number_of_#words  \n",
       "0     1.0      69                      [#earthquake]                 1  \n",
       "1     1.0      38                                 []                 0  \n",
       "2     1.0     133                                 []                 0  \n",
       "3     1.0      65                       [#wildfires]                 1  \n",
       "4     1.0      88              [#alaska, #wildfires]                 2  \n",
       "5     1.0     110  [#rockyfire, #cafire, #wildfires]                 3  \n",
       "6     1.0      95                [#flood, #disaster]                 2  \n",
       "7     1.0      59                                 []                 0  \n",
       "8     1.0      79                                 []                 0  \n",
       "9     1.0      52                                 []                 0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>#word</th>\n",
       "      <th>number_of_#words</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>[#earthquake]</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this # earthquake ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask . canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>all residents asked to 'shelter in place ' are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>[#wildfires]</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive # wildfires evacuation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>[#alaska, #wildfires]</td>\n",
       "      <td>2</td>\n",
       "      <td>just got sent this photo from ruby # alaska as...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this #earthquake m...   \n",
       "1   4     NaN      NaN             forest fire near la ronge sask. canada   \n",
       "2   5     NaN      NaN  all residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby #alaska as ...   \n",
       "\n",
       "   target  length                  #word  number_of_#words  \\\n",
       "0     1.0      69          [#earthquake]                 1   \n",
       "1     1.0      38                     []                 0   \n",
       "2     1.0     133                     []                 0   \n",
       "3     1.0      65           [#wildfires]                 1   \n",
       "4     1.0      88  [#alaska, #wildfires]                 2   \n",
       "\n",
       "                                      processed_text  \n",
       "0  our deeds are the reason of this # earthquake ...  \n",
       "1            forest fire near la ronge sask . canada  \n",
       "2  all residents asked to 'shelter in place ' are...  \n",
       "3  13,000 people receive # wildfires evacuation o...  \n",
       "4  just got sent this photo from ruby # alaska as...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenisation\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "data['processed_text'] = data['text'].apply(lambda x : \" \".join(word_tokenize(x)))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>#word</th>\n",
       "      <th>number_of_#words</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>[#earthquake]</td>\n",
       "      <td>1</td>\n",
       "      <td>deeds reason # earthquake may allah forgive us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask . canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>residents asked 'shelter place ' notified offi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>[#wildfires]</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive # wildfires evacuation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>[#alaska, #wildfires]</td>\n",
       "      <td>2</td>\n",
       "      <td>got sent photo ruby # alaska smoke # wildfires...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this #earthquake m...   \n",
       "1   4     NaN      NaN             forest fire near la ronge sask. canada   \n",
       "2   5     NaN      NaN  all residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby #alaska as ...   \n",
       "\n",
       "   target  length                  #word  number_of_#words  \\\n",
       "0     1.0      69          [#earthquake]                 1   \n",
       "1     1.0      38                     []                 0   \n",
       "2     1.0     133                     []                 0   \n",
       "3     1.0      65           [#wildfires]                 1   \n",
       "4     1.0      88  [#alaska, #wildfires]                 2   \n",
       "\n",
       "                                      processed_text  \n",
       "0     deeds reason # earthquake may allah forgive us  \n",
       "1            forest fire near la ronge sask . canada  \n",
       "2  residents asked 'shelter place ' notified offi...  \n",
       "3  13,000 people receive # wildfires evacuation o...  \n",
       "4  got sent photo ruby # alaska smoke # wildfires...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing stopwords\n",
    "stop= stopwords.words('english')\n",
    "\n",
    "data['processed_text'] = data['processed_text'].apply(lambda x: \" \".join([word for word in x.split() if word not in stop]))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>#word</th>\n",
       "      <th>number_of_#words</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>[#earthquake]</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason # earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask . canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>resident asked 'shelter place ' notified offic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>[#wildfires]</td>\n",
       "      <td>1</td>\n",
       "      <td>13,000 people receive # wildfire evacuation or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>[#alaska, #wildfires]</td>\n",
       "      <td>2</td>\n",
       "      <td>got sent photo ruby # alaska smoke # wildfire ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this #earthquake m...   \n",
       "1   4     NaN      NaN             forest fire near la ronge sask. canada   \n",
       "2   5     NaN      NaN  all residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby #alaska as ...   \n",
       "\n",
       "   target  length                  #word  number_of_#words  \\\n",
       "0     1.0      69          [#earthquake]                 1   \n",
       "1     1.0      38                     []                 0   \n",
       "2     1.0     133                     []                 0   \n",
       "3     1.0      65           [#wildfires]                 1   \n",
       "4     1.0      88  [#alaska, #wildfires]                 2   \n",
       "\n",
       "                                      processed_text  \n",
       "0       deed reason # earthquake may allah forgive u  \n",
       "1            forest fire near la ronge sask . canada  \n",
       "2  resident asked 'shelter place ' notified offic...  \n",
       "3  13,000 people receive # wildfire evacuation or...  \n",
       "4  got sent photo ruby # alaska smoke # wildfire ...  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "#data['processed_text'].apply(lambda x: lem.lemmatize(x))\n",
    "\n",
    "data['processed_text'] = data['processed_text'].apply(lambda x: \" \".join([lem.lemmatize(word) for word in x.split()]))\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stem = PorterStemmer()\n",
    "\n",
    "data['text'].apply(lambda x: \" \".join([stem.stem(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>#word</th>\n",
       "      <th>number_of_#words</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>[#earthquake]</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason  earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask  canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>resident asked shelter place  notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>[#wildfires]</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive  wildfire evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>[#alaska, #wildfires]</td>\n",
       "      <td>2</td>\n",
       "      <td>got sent photo ruby  alaska smoke  wildfire po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#rockyfire update =&gt; california hwy. 20 closed...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>[#rockyfire, #cafire, #wildfires]</td>\n",
       "      <td>3</td>\n",
       "      <td>rockyfire update   california hwy  20 closed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster heavy rain causes flash flood...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95</td>\n",
       "      <td>[#flood, #disaster]</td>\n",
       "      <td>2</td>\n",
       "      <td>flood  disaster heavy rain cause flash floodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm on top of the hill and i can see a fire in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>m top hill see fire wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there's an emergency evacuation happening now ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>s emergency evacuation happening building acro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>m afraid tornado coming area</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this #earthquake m...   \n",
       "1   4     NaN      NaN             forest fire near la ronge sask. canada   \n",
       "2   5     NaN      NaN  all residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby #alaska as ...   \n",
       "5   8     NaN      NaN  #rockyfire update => california hwy. 20 closed...   \n",
       "6  10     NaN      NaN  #flood #disaster heavy rain causes flash flood...   \n",
       "7  13     NaN      NaN  i'm on top of the hill and i can see a fire in...   \n",
       "8  14     NaN      NaN  there's an emergency evacuation happening now ...   \n",
       "9  15     NaN      NaN  i'm afraid that the tornado is coming to our a...   \n",
       "\n",
       "   target  length                              #word  number_of_#words  \\\n",
       "0     1.0      69                      [#earthquake]                 1   \n",
       "1     1.0      38                                 []                 0   \n",
       "2     1.0     133                                 []                 0   \n",
       "3     1.0      65                       [#wildfires]                 1   \n",
       "4     1.0      88              [#alaska, #wildfires]                 2   \n",
       "5     1.0     110  [#rockyfire, #cafire, #wildfires]                 3   \n",
       "6     1.0      95                [#flood, #disaster]                 2   \n",
       "7     1.0      59                                 []                 0   \n",
       "8     1.0      79                                 []                 0   \n",
       "9     1.0      52                                 []                 0   \n",
       "\n",
       "                                      processed_text  \n",
       "0        deed reason  earthquake may allah forgive u  \n",
       "1             forest fire near la ronge sask  canada  \n",
       "2  resident asked shelter place  notified officer...  \n",
       "3  13000 people receive  wildfire evacuation orde...  \n",
       "4  got sent photo ruby  alaska smoke  wildfire po...  \n",
       "5   rockyfire update   california hwy  20 closed ...  \n",
       "6   flood  disaster heavy rain cause flash floodi...  \n",
       "7                          m top hill see fire wood   \n",
       "8  s emergency evacuation happening building acro...  \n",
       "9                      m afraid tornado coming area   "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text):\n",
    "    # Define a list of special characters to remove\n",
    "    special_chars = \"!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\n",
    "\n",
    "    # Remove special characters using str.translate() method\n",
    "    cleaned_text = text.translate(str.maketrans('', '', special_chars))\n",
    "    return cleaned_text\n",
    "\n",
    "data['processed_text']=data['processed_text'].apply(lambda x: remove_special_characters(x))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>#word</th>\n",
       "      <th>number_of_#words</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this #earthquake m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>69</td>\n",
       "      <td>[#earthquake]</td>\n",
       "      <td>1</td>\n",
       "      <td>deed reason  earthquake may allah forgive u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask. canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>forest fire near la ronge sask  canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>resident asked shelter place  notified officer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>[#wildfires]</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive  wildfire evacuation orde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby #alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "      <td>[#alaska, #wildfires]</td>\n",
       "      <td>2</td>\n",
       "      <td>got sent photo ruby  alaska smoke  wildfire po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#rockyfire update =&gt; california hwy. 20 closed...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>110</td>\n",
       "      <td>[#rockyfire, #cafire, #wildfires]</td>\n",
       "      <td>3</td>\n",
       "      <td>rockyfire update   california hwy  20 closed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood #disaster heavy rain causes flash flood...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95</td>\n",
       "      <td>[#flood, #disaster]</td>\n",
       "      <td>2</td>\n",
       "      <td>flood  disaster heavy rain cause flash floodi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm on top of the hill and i can see a fire in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>m top hill see fire wood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there's an emergency evacuation happening now ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>s emergency evacuation happening building acro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i'm afraid that the tornado is coming to our a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>m afraid tornado coming area</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>three people died from the heat wave so far</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>three people died heat wave far</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>haha south tampa is getting flooded hah- wait ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>129</td>\n",
       "      <td>[#flooding]</td>\n",
       "      <td>1</td>\n",
       "      <td>haha south tampa getting flooded hah wait seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#raining #flooding #florida #tampabay #tampa 1...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76</td>\n",
       "      <td>[#raining, #flooding, #florida, #tampabay, #ta...</td>\n",
       "      <td>5</td>\n",
       "      <td>raining  flooding  florida  tampabay  tampa 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#flood in bago myanmar #we arrived bago</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39</td>\n",
       "      <td>[#flood, #we]</td>\n",
       "      <td>2</td>\n",
       "      <td>flood bago myanmar  arrived bago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>damage to school bus on 80 in multi car crash ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>[#breaking]</td>\n",
       "      <td>1</td>\n",
       "      <td>damage school bus 80 multi car crash  breaking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what's up man?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>s man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i love fruits</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>love fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>summer is lovely</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>summer lovely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>my car is so fast</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>car fast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>what a goooooooaaaaaal!!!!!!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>goooooooaaaaaal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id keyword location                                               text  \\\n",
       "0    1     NaN      NaN  our deeds are the reason of this #earthquake m...   \n",
       "1    4     NaN      NaN             forest fire near la ronge sask. canada   \n",
       "2    5     NaN      NaN  all residents asked to 'shelter in place' are ...   \n",
       "3    6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4    7     NaN      NaN  just got sent this photo from ruby #alaska as ...   \n",
       "5    8     NaN      NaN  #rockyfire update => california hwy. 20 closed...   \n",
       "6   10     NaN      NaN  #flood #disaster heavy rain causes flash flood...   \n",
       "7   13     NaN      NaN  i'm on top of the hill and i can see a fire in...   \n",
       "8   14     NaN      NaN  there's an emergency evacuation happening now ...   \n",
       "9   15     NaN      NaN  i'm afraid that the tornado is coming to our a...   \n",
       "10  16     NaN      NaN        three people died from the heat wave so far   \n",
       "11  17     NaN      NaN  haha south tampa is getting flooded hah- wait ...   \n",
       "12  18     NaN      NaN  #raining #flooding #florida #tampabay #tampa 1...   \n",
       "13  19     NaN      NaN            #flood in bago myanmar #we arrived bago   \n",
       "14  20     NaN      NaN  damage to school bus on 80 in multi car crash ...   \n",
       "15  23     NaN      NaN                                     what's up man?   \n",
       "16  24     NaN      NaN                                      i love fruits   \n",
       "17  25     NaN      NaN                                   summer is lovely   \n",
       "18  26     NaN      NaN                                  my car is so fast   \n",
       "19  28     NaN      NaN                       what a goooooooaaaaaal!!!!!!   \n",
       "\n",
       "    target  length                                              #word  \\\n",
       "0      1.0      69                                      [#earthquake]   \n",
       "1      1.0      38                                                 []   \n",
       "2      1.0     133                                                 []   \n",
       "3      1.0      65                                       [#wildfires]   \n",
       "4      1.0      88                              [#alaska, #wildfires]   \n",
       "5      1.0     110                  [#rockyfire, #cafire, #wildfires]   \n",
       "6      1.0      95                                [#flood, #disaster]   \n",
       "7      1.0      59                                                 []   \n",
       "8      1.0      79                                                 []   \n",
       "9      1.0      52                                                 []   \n",
       "10     1.0      43                                                 []   \n",
       "11     1.0     129                                        [#flooding]   \n",
       "12     1.0      76  [#raining, #flooding, #florida, #tampabay, #ta...   \n",
       "13     1.0      39                                      [#flood, #we]   \n",
       "14     1.0      56                                        [#breaking]   \n",
       "15     0.0      14                                                 []   \n",
       "16     0.0      13                                                 []   \n",
       "17     0.0      16                                                 []   \n",
       "18     0.0      17                                                 []   \n",
       "19     0.0      28                                                 []   \n",
       "\n",
       "    number_of_#words                                     processed_text  \n",
       "0                  1        deed reason  earthquake may allah forgive u  \n",
       "1                  0             forest fire near la ronge sask  canada  \n",
       "2                  0  resident asked shelter place  notified officer...  \n",
       "3                  1  13000 people receive  wildfire evacuation orde...  \n",
       "4                  2  got sent photo ruby  alaska smoke  wildfire po...  \n",
       "5                  3   rockyfire update   california hwy  20 closed ...  \n",
       "6                  2   flood  disaster heavy rain cause flash floodi...  \n",
       "7                  0                          m top hill see fire wood   \n",
       "8                  0  s emergency evacuation happening building acro...  \n",
       "9                  0                      m afraid tornado coming area   \n",
       "10                 0                    three people died heat wave far  \n",
       "11                 1  haha south tampa getting flooded hah wait seco...  \n",
       "12                 5   raining  flooding  florida  tampabay  tampa 1...  \n",
       "13                 2                   flood bago myanmar  arrived bago  \n",
       "14                 1     damage school bus 80 multi car crash  breaking  \n",
       "15                 0                                             s man   \n",
       "16                 0                                         love fruit  \n",
       "17                 0                                      summer lovely  \n",
       "18                 0                                           car fast  \n",
       "19                 0                              goooooooaaaaaal        "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negation handling\n",
    "\n",
    "from nltk.sentiment.util import mark_negation\n",
    "\n",
    "\n",
    "data['processed_text']=data['processed_text'].apply(lambda x: ''.join(mark_negation(x)))\n",
    "data.head(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All till now in one function :P\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Join the tokens back into a single string\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "\n",
    "# Apply text cleaning\n",
    "data['processed_text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Display the DataFrame with cleaned text\n",
    "data.head(10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_spelling(text):\n",
    "    corrected_words = []\n",
    "    words = text.split()\n",
    "\n",
    "    # Correct spelling of each word\n",
    "    for word in words:\n",
    "        corrected_word = spell.correction(word)\n",
    "        corrected_words.append(corrected_word)\n",
    "\n",
    "    corrected_text = ' '.join(corrected_words)\n",
    "    return corrected_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              ded reason earthquake may alah forgive u\n",
       "1                 forest fire near la ronge sask canada\n",
       "2     resident asked shelter place notified oficer e...\n",
       "3     130 people receive wildfire evacuation order c...\n",
       "4     got sent photo ruby alaska smoke wildfire pour...\n",
       "5      rockyfire update california hwy 20 closed dir...\n",
       "6      flod disaster heavy rain cause flash floding ...\n",
       "7                                m top hil se fire wod \n",
       "8     s emergency evacuation hapening building acros...\n",
       "9                         m afraid tornado coming area \n",
       "10                       thre people died heat wave far\n",
       "11    haha south tampa geting floded hah wait second...\n",
       "12     raining floding florida tampabay tampa 18 19 ...\n",
       "13                        flod bago myanmar arived bago\n",
       "14         damage schol bus 80 multi car crash breaking\n",
       "15                                               s man \n",
       "16                                           love fruit\n",
       "17                                         sumer lovely\n",
       "18                                             car fast\n",
       "19                                                goal \n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def remove_repeated_characters(text):\n",
    "    # Remove repeated characters using regex\n",
    "    corrected_text = re.sub(r'(.)\\1+', r'\\1', text)\n",
    "    return corrected_text\n",
    "\n",
    "data['processed_text'].apply(remove_repeated_characters).head(20)\n",
    "\n",
    "# not using as it removed even if a letter occurs twice contiuously in a word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    pattern = r'http\\S+'  # Regex pattern to match URLs\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "data['processed_text']=data['processed_text'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and train\n",
    "\n",
    "i = train.shape[0]\n",
    "train = data[:i]\n",
    "test = data[i:]\n",
    "\n",
    "x=train['processed_text']\n",
    "y=train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,  x_val, y_train, y_val = train_test_split(x,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2644           new weapon cause unimaginable destruction \n",
       "2227    f   amp   ing thing  gishwhes got soaked delug...\n",
       "5448    dt  georgegalloway  rt  galloway4mayor  ûïthe...\n",
       "132     aftershock back school kick great  want thank ...\n",
       "6845    response trauma child addict develop defensive...\n",
       "Name: processed_text, dtype: object"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction: CountVectorizer(max_features=3000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def transformation(fe):\n",
    "    print(\"Feature Extraction:\", fe)\n",
    "    fe.fit(x_train)\n",
    "\n",
    "    x_train_fe = fe.transform(x_train).toarray()\n",
    "    x_val_fe = fe.transform(x_val).toarray()\n",
    "\n",
    "    test_fe = fe.transform(test['processed_text']).toarray()\n",
    "    \n",
    "    return (x_train_fe, x_val_fe, test_fe)\n",
    "\n",
    "maxf = 3000\n",
    "cv = CountVectorizer(max_features=maxf)\n",
    "tfidf = TfidfVectorizer(max_features=maxf)\n",
    "\n",
    "x_train_fe, x_val_fe, test_fe = transformation(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_fe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction Techniques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Reduction: PCA(n_components=2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def reduce_dimension(technique):\n",
    "    print(\"Feature Reduction:\", technique)\n",
    "    technique.fit(x_train_fe)\n",
    "    \n",
    "    x_train_fe_r = technique.transform(x_train_fe)\n",
    "    x_val_fe_r = technique.transform(x_val_fe)\n",
    "\n",
    "    test_fe_r = technique.transform(test_fe)\n",
    "\n",
    "    return( x_train_fe_r, x_val_fe_r, test_fe_r)\n",
    "\n",
    "\n",
    "\n",
    "n=2\n",
    "svd = TruncatedSVD(n_components=n)  # Specify the number of components to keep\n",
    "pca = PCA(n_components=n)\n",
    "\n",
    "x_train_fe_r, x_val_fe_r, test_fe_r = reduce_dimension(pca)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing models\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  LogisticRegression()\n",
      "\n",
      "no feature reduction\n",
      "No exception occurred.\n",
      "Classification Report for Validation set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.80      0.83       940\n",
      "         1.0       0.71      0.79      0.75       583\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.79      0.80      0.79      1523\n",
      "weighted avg       0.80      0.80      0.80      1523\n",
      "\n",
      "\n",
      "value_counts of validation set predictions:\n",
      " 0.0    940\n",
      "1.0    583\n",
      "dtype: int64\n",
      "\n",
      "value_counts of test predictions:\n",
      " 0.0    2080\n",
      "1.0    1183\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def modeling(model):\n",
    "    print(\"Model: \",model)\n",
    "    print()\n",
    "    try:\n",
    "        # Code to be executed\n",
    "        model.fit(x_train_fe, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(x_train_fe)\n",
    "\n",
    "        y_pred = model.predict(x_val_fe)\n",
    "\n",
    "        test_pred = model.predict(test_fe)\n",
    "        print(\"no feature reduction\")\n",
    "\n",
    "    except ValueError as ve:\n",
    "        # Code to handle the ValueError exception\n",
    "        print(\"ValueError!\")\n",
    "        model.fit(x_train_fe_r, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(x_train_fe_r)\n",
    "\n",
    "        y_pred = model.predict(x_val_fe_r)\n",
    "\n",
    "        test_pred = model.predict(test_fe_r)\n",
    "\n",
    "    else:\n",
    "        # Code to be executed if no exception occurs\n",
    "        print(\"No exception occurred.\")\n",
    "\n",
    "    finally:\n",
    "        # Code to be executed regardless of whether an exception occurred or not \n",
    "        # print(\"Classification Report for train set:\")\n",
    "        # print(classification_report(y_train_pred, y_train))\n",
    "\n",
    "        print(\"Classification Report for Validation set:\")\n",
    "        print(classification_report(y_pred, y_val))\n",
    "\n",
    "        # print(\"confusion matrix\")\n",
    "        # print(confusion_matrix(y_pred, y_val))\n",
    "\n",
    "        print(\"\\nvalue_counts of validation set predictions:\\n\", pd.DataFrame(y_pred).value_counts())\n",
    "\n",
    "        print(\"\\nvalue_counts of test predictions:\\n\", pd.DataFrame(test_pred).value_counts())\n",
    "\n",
    "    return test_pred\n",
    "\n",
    "\n",
    "\n",
    "instance_lr = LogisticRegression()\n",
    "instance_dtc = DecisionTreeClassifier()\n",
    "instance_rfc = RandomForestClassifier()\n",
    "instance_svm = svm.SVC()\n",
    "instance_mnb = MultinomialNB()\n",
    "\n",
    "\n",
    "submission['target']= modeling(instance_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction: TfidfVectorizer(max_features=3000)\n",
      "Feature Reduction: PCA(n_components=7)\n",
      "Model:  LogisticRegression()\n",
      "\n",
      "no feature reduction\n",
      "No exception occurred.\n",
      "Classification Report for Validation set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.79      0.84       972\n",
      "         1.0       0.69      0.81      0.75       551\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.79      0.80      0.79      1523\n",
      "weighted avg       0.81      0.80      0.80      1523\n",
      "\n",
      "\n",
      "value_counts of validation set predictions:\n",
      " 0.0    972\n",
      "1.0    551\n",
      "dtype: int64\n",
      "\n",
      "value_counts of test predictions:\n",
      " 0.0    2118\n",
      "1.0    1145\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Features extraction\n",
    "maxf = 3000\n",
    "cv = CountVectorizer(max_features=maxf)\n",
    "tfidf = TfidfVectorizer(max_features=maxf)\n",
    "x_train_fe, x_val_fe, test_fe = transformation(tfidf)\n",
    "\n",
    "# features reduction\n",
    "n=7\n",
    "svd = TruncatedSVD(n_components=n)  # Specify the number of components to keep\n",
    "pca = PCA(n_components=n)\n",
    "\n",
    "x_train_fe_r, x_val_fe_r, test_fe_r = reduce_dimension(pca)\n",
    "\n",
    "# model train and prediction\n",
    "instance_lr = LogisticRegression()\n",
    "instance_dtc = DecisionTreeClassifier()\n",
    "instance_rfc = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "instance_svm = svm.SVC()\n",
    "instance_mnb = MultinomialNB()\n",
    "\n",
    "\n",
    "submission['target']= modeling(instance_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2118\n",
      "1    1145\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = submission['target'].apply(lambda x: round(x))\n",
    "#submission.to_csv(\"/Users/ankitbaliyan/Documents/VS_Code/Ongoing projects/NLP_Disaster/subission file/submission_7.csv\", index=False)\n",
    "print(submission.target.value_counts())\n",
    "submission.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "-# Create a pipeline with TfidfVectorizer, PCA, and RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svd', TruncatedSVD()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "-# Define the parameter grid for grid search\n",
    "parameters = {\n",
    "    'svd__n_components': range(2, 101, 5),         # Values for n_components in TruncatedSVD\n",
    "    'tfidf__max_features': range(500, 1001, 100),  # Values for max_features in TfidfVectorizer\n",
    "    'classifier__n_estimators': [100, 200, 300]    # Values for n_estimators in RandomForestClassifier\n",
    "}\n",
    "\n",
    "-# Create an instance of GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=3)\n",
    "\n",
    "-# Perform grid search on the corpus\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "-# Get the best parameters and the corresponding score\n",
    "best_parameters = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitbaliyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8076165462902167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitbaliyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/ankitbaliyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "/Users/ankitbaliyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# split test and train\n",
    "\n",
    "i = train.shape[0]\n",
    "train = data[:i]\n",
    "test = data[i:]\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into features (text and length) and target\n",
    "X = train[['processed_text', 'length','number_of_#words']]\n",
    "y = train['target']\n",
    "test = test[['processed_text','length','number_of_#words']]\n",
    "\n",
    "# Convert text to numerical representation using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "vectorizer.fit(X['processed_text'])\n",
    "X_text = vectorizer.transform(X['processed_text'])\n",
    "test_text = vectorizer.transform(test['processed_text'])\n",
    "\n",
    "# Combine text and length features\n",
    "X_combined = pd.concat([pd.DataFrame(X_text.toarray()), X[['length','number_of_#words']]], axis=1)\n",
    "test_combined = pd.concat([pd.DataFrame(test_text.toarray()), test[['length','number_of_#words']]], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "submission['target']=model.predict(test_combined)\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitbaliyan/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "submission['target']=model.predict(test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2087\n",
      "1    1176\n",
      "Name: target, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['target'] = submission['target'].apply(lambda x: round(x))\n",
    "#submission.to_csv(\"/Users/ankitbaliyan/Documents/VS_Code/Ongoing projects/NLP_Disaster/subission file/submission_9.csv\", index=False)\n",
    "print(submission.target.value_counts())\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
